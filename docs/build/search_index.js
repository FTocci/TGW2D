var documenterSearchIndex = {"docs":
[{"location":"dgx/#DGX-1","page":"Macchina DGX-1","title":"DGX-1","text":"","category":"section"},{"location":"dgx/","page":"Macchina DGX-1","title":"Macchina DGX-1","text":"Nvidia DGX è una linea di server e workstation prodotti da NVIDIA e specializzati nell'uso di GPGPU per accelerare le applicazioni di deep learning. Il componente principale di un sistema DGX è un insieme di 4-16 moduli GPU Nvidia Tesla su una scheda di sistema indipendente. I sistemi DGX sono dotati di grandi dissipatori e potenti ventole per raffreddare adeguatamente migliaia di watt di potenza termica. I moduli GPU sono tipicamente integrati nel sistema utilizzando una versione del socket SXM.","category":"page"},{"location":"dgx/","page":"Macchina DGX-1","title":"Macchina DGX-1","text":"I server DGX-1 dispongono di 8 GPU basate sulle schede figlie Pascal o Volta con 128 GB di memoria HBM2 totale, collegate da una rete mesh NVLink. Il DGX-1 è stato annunciato il 6 aprile 2016. Tutti i modelli sono basati su una configurazione dual socket di CPU Intel Xeon E5 e sono dotati delle seguenti caratteristiche:","category":"page"},{"location":"dgx/","page":"Macchina DGX-1","title":"Macchina DGX-1","text":"512 GB di DDR4-2133\nDual 10Gb Networking\n4 unità SSD da 1,92 TB\nCapacità di alimentazione combinata di 3200 W\nTelaio con montaggio a rack 3U","category":"page"},{"location":"dgx/#Test-su-macchina","page":"Macchina DGX-1","title":"Test su macchina","text":"","category":"section"},{"location":"dgx/","page":"Macchina DGX-1","title":"Macchina DGX-1","text":"Per verificare ulteriormente i benefici apportati dal Multithreading è stato scelto di eseguire l'algoritmo su una macchina che consentisse l'impiego di molti thread. In tal senso, è stata impiegata la macchina DGX-1.","category":"page"},{"location":"dgx/","page":"Macchina DGX-1","title":"Macchina DGX-1","text":"In particolare sono stati lanciati 32 thread.","category":"page"},{"location":"dgx/","page":"Macchina DGX-1","title":"Macchina DGX-1","text":"(Image: nthreads)","category":"page"},{"location":"dgx/","page":"Macchina DGX-1","title":"Macchina DGX-1","text":"(Image: risultato)","category":"page"},{"location":"dgx/","page":"Macchina DGX-1","title":"Macchina DGX-1","text":"Eseguendo i medesimi test sopra riportati, la macchina ha fornito il risultato illustrato nell'immagine precedente.","category":"page"},{"location":"dgx/","page":"Macchina DGX-1","title":"Macchina DGX-1","text":"In proporzione, il tempo impiegato è diminuito del 42%.","category":"page"},{"location":"intro/#Topological-Gift-Wrapping-2D-TGW2D","page":"Introduzione","title":"Topological Gift Wrapping 2D - TGW2D","text":"","category":"section"},{"location":"intro/","page":"Introduzione","title":"Introduzione","text":"Il topological gift wrapping è un algoritmo che produce un insieme di complessi di catene in 2D.  Data una qualsiasi collezione di poliedri cellulari la computazione può essere riassunta con i seguenti passaggi:","category":"page"},{"location":"intro/","page":"Introduzione","title":"Introduzione","text":"Estrarre i due scheletri dei poliedri;\nFondere in modo efficiente tutte le loro 2-celle;\nCalcolare su ogni 2-cella il suo complesso di catene locale.","category":"page"},{"location":"intro/","page":"Introduzione","title":"Introduzione","text":"Con tali premesse, l’obiettivo del presente elaborato è stato quello di effettuare una analisi preliminare del codice a disposizione, individuando i compiti principali che l’algoritmo svolge, le dipendenze fra le varie funzione che lo compongono e determinare  eventuali criticità su cui è necessario intervenire.","category":"page"},{"location":"intro/#Linguaggio-Julia","page":"Introduzione","title":"Linguaggio Julia","text":"","category":"section"},{"location":"intro/","page":"Introduzione","title":"Introduzione","text":"L’algoritmo appena introdotto utilizza Julia come linguaggio di programmazione. Essoè stato creato con l’intento di garantire alte prestazioni, sfruttando a pieno lepotenzialità  del calcolo parallelo. È possibile utilizzare primitive che permettono di sfruttare a pieno i core delle macchine sulle quali viene messo in esecuzione il codiceJulia, grazie al  meccanismo di multi-threading. Julia può inoltre generare codice nativo per GPU, risorsa che permette di abbattere ulteriormente i tempi di esecuzione dell’algoritmo.","category":"page"},{"location":"intro/#Funzionamento","page":"Introduzione","title":"Funzionamento","text":"","category":"section"},{"location":"intro/","page":"Introduzione","title":"Introduzione","text":"L’algoritmo è utilizzato localmente su 2-cella per essere decomposta, e invece utilizzato  globalmente per generare le 3-celle della partizione dello spazio.","category":"page"},{"location":"intro/","page":"Introduzione","title":"Introduzione","text":"(Image: Cycle Extraction)","category":"page"},{"location":"intro/","page":"Introduzione","title":"Introduzione","text":"Per ogni elemento (1-scheletro) calcolo il bordo ottenendo i due vertici, per ciascun vertice calcolo il cobordo, ovvero individuo gli altri elementi (1-scheletro) con un vertice  coincidente (questo passaggio viene effettuato tramite valori matriciali). A questo punto  si isolano due elementi tra quelli individuati formando così una catena e si ripete  l’algoritmo sugli elementi della catena appena calcolata. L’obiettivo di ciascuna iterazione è quello di individuare una porzione nel piano (ovvero la 1-catenadi bordo)","category":"page"},{"location":"intro/#Illustrazione-dello-pseudocodice","page":"Introduzione","title":"Illustrazione dello pseudocodice","text":"","category":"section"},{"location":"intro/","page":"Introduzione","title":"Introduzione","text":"Lo pseudocodice è il riassunto dell’algoritmo TGW in uno spazio generico di D-dimensionale. L’algoritmo prende in input una matrice sparsa di dimensioni “m×n” e restituisce una matrice dal dominio delle D-catene a quello dei (d-1) cicli orientati.","category":"page"},{"location":"intro/","page":"Introduzione","title":"Introduzione","text":"(Image: pseudocode)","category":"page"},{"location":"prestazioni/#Analisi-delle-Prestazioni","page":"Analisi delle prestazioni","title":"Analisi delle Prestazioni","text":"","category":"section"},{"location":"prestazioni/","page":"Analisi delle prestazioni","title":"Analisi delle prestazioni","text":"Nel presente capitolo vengono analizzate le prestazioni prima e dopo le  modifiche implementate. In particolare, sono stati misurati i tempi di esecuzione del codice iniziale. In seguito, sono state apportate modifiche al codice al fine di gestire i 'colli di bottiglia' individuati. Infine, sono stati ricalcolati i tempi di esecuzione dell'algoritmo e confrontati con quelli di partenza.","category":"page"},{"location":"prestazioni/#Situazione-di-partenza","page":"Analisi delle prestazioni","title":"Situazione di partenza","text":"","category":"section"},{"location":"prestazioni/","page":"Analisi delle prestazioni","title":"Analisi delle prestazioni","text":"(Image: iniziale)","category":"page"},{"location":"prestazioni/#Test-Intermedi","page":"Analisi delle prestazioni","title":"Test Intermedi","text":"","category":"section"},{"location":"prestazioni/","page":"Analisi delle prestazioni","title":"Analisi delle prestazioni","text":"Dopo aver implementato il multithreading sono stati eseguiti dei test con 2 e 4 thread. Tuttavia, i tempi di esecuzione risultavano ancora instabili e non vi erano miglioramenti significativi.","category":"page"},{"location":"prestazioni/#Risultato-Finale","page":"Analisi delle prestazioni","title":"Risultato Finale","text":"","category":"section"},{"location":"prestazioni/","page":"Analisi delle prestazioni","title":"Analisi delle prestazioni","text":"Il test finale è stato eseguito con 8 thread portando ai seguenti risultati:","category":"page"},{"location":"prestazioni/","page":"Analisi delle prestazioni","title":"Analisi delle prestazioni","text":"(Image: finale)","category":"page"},{"location":"prestazioni/","page":"Analisi delle prestazioni","title":"Analisi delle prestazioni","text":"Come si evince dalla figura i tempi sono migliorati di circa il 15%.","category":"page"},{"location":"sviluppo/#Studio-Esecutivo","page":"Sviluppo","title":"Studio Esecutivo","text":"","category":"section"},{"location":"sviluppo/","page":"Sviluppo","title":"Sviluppo","text":"All’interno di questo capitolo verrà trattato lo sviluppo del progetto nella sua fase principale, ovvero quella riguardante la messa in atto di tutte le modifiche introdotte nel  capitolo precedente. Lo scopo principale è quello di migliorare le prestazioni dell’algoritmo preso in esame andando ad introdurre all’interno del codice porzioni che presentano la possibilità di essere eseguite in parallelo. Oltre a ciò, un secondo obiettivo è la re-fattorizzazione di alcune funzione, garantendo migliore scalabilità e modificabilità dei moduli interessati.","category":"page"},{"location":"sviluppo/#Calcolo-Parallelo-in-Julia","page":"Sviluppo","title":"Calcolo Parallelo in Julia","text":"","category":"section"},{"location":"sviluppo/","page":"Sviluppo","title":"Sviluppo","text":"Come introdotto nei paragrafi precedenti è stato deciso di migliorare le prestazioni dell’algoritmo usufruendo delle potenzialità garantite dal calcolo parallelo. Nei prossimi paragrafi verranno illustrate le possibili implementazioni del calcolo parallelo offerta dal linguaggio di programmazione Julia.","category":"page"},{"location":"sviluppo/#Task-asincroni-o-coroutine","page":"Sviluppo","title":"Task asincroni o coroutine","text":"","category":"section"},{"location":"sviluppo/","page":"Sviluppo","title":"Sviluppo","text":"I task di Julia consentono di sospendere e riprendere i calcoli per l'I/O, la gestione  degli eventi e modelli simili. I task possono sincronizzarsi attraverso operazioni come wait e fetch e comunicare tramite canali. Pur non essendo di per sé un calcolo parallelo, Julia consente di programmare i task su più thread.","category":"page"},{"location":"sviluppo/#Multithreading","page":"Sviluppo","title":"Multithreading","text":"","category":"section"},{"location":"sviluppo/","page":"Sviluppo","title":"Sviluppo","text":"Il multithreading di Julia offre la possibilità di programmare task simultaneamente su più di un thread o core della CPU, condividendo la memoria.  Questo è di solito il modo più semplice per ottenere il parallelismo sul proprio PC o su un singolo grande server multicore.","category":"page"},{"location":"sviluppo/#Elaborazione-distribuita","page":"Sviluppo","title":"Elaborazione distribuita","text":"","category":"section"},{"location":"sviluppo/","page":"Sviluppo","title":"Sviluppo","text":"Il calcolo distribuito esegue più processi Julia con spazi di memoria separati. Questi possono trovarsi sullo stesso computer o su più computer. La libreria standard Distributed fornisce la possibilità di eseguire in remoto una funzione Julia. Con questo blocco di base, è possibile costruire molti tipi diversi di astrazioni di calcolo distribuito.","category":"page"},{"location":"sviluppo/#Elaborazione-su-GPU","page":"Sviluppo","title":"Elaborazione su GPU","text":"","category":"section"},{"location":"sviluppo/","page":"Sviluppo","title":"Sviluppo","text":"Il compilatore Julia GPU offre la possibilità di eseguire codice Julia in modo nativo sulle GPU. Esiste un ricco ecosistema di pacchetti Julia che puntano alle GPU.","category":"page"},{"location":"sviluppo/#Analisi-del-Codice","page":"Sviluppo","title":"Analisi del Codice","text":"","category":"section"},{"location":"sviluppo/","page":"Sviluppo","title":"Sviluppo","text":"Prima dell’attuazione delle modifiche è stata svolta un’analisi dell’algoritmo con l’obiettivo di misurarne i tempi di esecuzione e di individuare eventuali porzioni di codice  che potessero rallentare notevolmente l’esecuzione dello stesso. In tal senso, Julia offre strumenti che possono aiutare a diagnosticare i problemi e a migliorare le prestazioni del codice. Per questa fase di studio dell’algoritmo sono stati usati:","category":"page"},{"location":"sviluppo/","page":"Sviluppo","title":"Sviluppo","text":"Profiling","category":"page"},{"location":"sviluppo/","page":"Sviluppo","title":"Sviluppo","text":"La profilazione consente di misurare le prestazioni del codice in esecuzione e di identificare le linee che fungono da colli di bottiglia. Per la visualizzazione dei risultati è stato usato il pacchetto ProfileView.","category":"page"},{"location":"sviluppo/","page":"Sviluppo","title":"Sviluppo","text":"@time","category":"page"},{"location":"sviluppo/","page":"Sviluppo","title":"Sviluppo","text":"Una macro che esegue un'espressione, stampando il tempo di esecuzione, il numero di allocazioni e il numero totale di byte che l'esecuzione ha causato, prima di restituire il valore dell'espressione.","category":"page"},{"location":"sviluppo/","page":"Sviluppo","title":"Sviluppo","text":"(Image: Profile)","category":"page"},{"location":"sviluppo/#Implementazione-delle-modifiche","page":"Sviluppo","title":"Implementazione delle modifiche","text":"","category":"section"},{"location":"sviluppo/","page":"Sviluppo","title":"Sviluppo","text":"All’interno dell’algoritmo è evidente una elevata presenza di cicli, molti dei quali  annidati. Per questo motivo è stato scelto di utilizzare la tecnica del Multi-threading e in  particolare, Julia supporta i loop paralleli utilizzando la macro Threads.@threads. Questa  macro viene apposta davanti a un ciclo for per indicare a Julia che il ciclo è una regione  multi-thread.","category":"page"},{"location":"sviluppo/","page":"Sviluppo","title":"Sviluppo","text":"Lo spazio di iterazione viene suddiviso tra i thread, dopodiché ogni thread scrive il proprio ID thread nelle posizioni assegnate. Prima di eseguire un programma Julia multithread, è necessario impostare il numero di thread. Questo può essere impostato dalla  linea di comando di Julia, utilizzando gli argomenti della riga di comando -t, o  modificando la variabile d'ambiente JULIANUMTHREADS.","category":"page"},{"location":"sviluppo/#Re-fattorizzazione","page":"Sviluppo","title":"Re-fattorizzazione","text":"","category":"section"},{"location":"sviluppo/","page":"Sviluppo","title":"Sviluppo","text":"Come anticipato nei paragrafi precedenti è stato scelto di aggiungere alcune nuove funzioni all’interno del codice così da ridurre le responsabilità di alcuni metodi già presenti nello stesso. Questa scelta implementativa ha coinvolto prevalentemente la funzione “merge_vertices”, il cui corpo al termine delle modifiche è risultato  notevolmente più leggibile. In particolare, le funzioni che sono state aggiunte nel codice  sono mergeCongruentVertices, mergeCongruentEdges e buildEdgeMap.","category":"page"},{"location":"sviluppo/","page":"Sviluppo","title":"Sviluppo","text":"function mergeCongruentVertices(vertsnum,newverts,kdtree,V,err=1e-4)\r\n    todelete = []\r\n    i = 1\r\n    for vi in 1:vertsnum\r\n        if !(vi in todelete)\r\n            nearvs = Lar.inrange(kdtree, V[vi, :], err)\r\n            newverts[nearvs] .= i\r\n            nearvs = setdiff(nearvs, vi)\r\n            todelete = union(todelete, nearvs)\r\n            i = i + 1\r\n        end\r\n    end\r\n    return todelete,newverts\r\nend\r\n\r\nfunction mergeCongruentEdges(edgenum,newverts,EV)\r\n    edges = Array{Tuple{Int, Int}, 1}(undef, edgenum)\r\n    oedges = Array{Tuple{Int, Int}, 1}(undef, edgenum)\r\n    @sync begin\r\n        for ei in 1:edgenum\r\n            @async begin\r\n                v1, v2 = EV[ei, :].nzind\r\n                edges[ei] = Tuple{Int, Int}(sort([newverts[v1], newverts[v2]]))\r\n                oedges[ei] = Tuple{Int, Int}(sort([v1, v2])) \r\n            end\r\n        end \r\n    end\r\n    return edges,oedges\r\nend\r\n\r\nfunction buildEdgeMap(nedges,nedgenum,nEV,etuple2idx,edge_map,edges)\r\n    for ei in 1:nedgenum\r\n        nEV[ei, collect(nedges[ei])] .= 1\r\n        etuple2idx[nedges[ei]] = ei\r\n    end\r\n    \r\n    for i in 1:length(edge_map)\r\n        row = edge_map[i]\r\n        row = map(x->edges[x], row)\r\n        row = filter(t->t[1]!=t[2], row)\r\n        row = map(x->etuple2idx[x], row)\r\n        edge_map[i] = row \r\n    end        \r\n    return edge_map,nEV\r\nend\r\n","category":"page"},{"location":"grafodipendenze/#Grafo-delle-Dipendenze","page":"Grafo delle Dipendenze","title":"Grafo delle Dipendenze","text":"","category":"section"},{"location":"grafodipendenze/","page":"Grafo delle Dipendenze","title":"Grafo delle Dipendenze","text":"In questa sezione è rappresentato il grafo orientato delle dipendenze della base di codice oggetto di studio. Ogni arco orientato rappresenta una chiamata di funzione (v_1 v_2), dove v_1 è la funzione chiamante, e v_2 è la funzione chiamata. I nodi hanno un’etichetta corrispondente al nome della funzione. Gli archi invece hanno una etichetta numerica consecutiva corrispondente all’ordine delle chiamate dal nodo loro origine.","category":"page"},{"location":"grafodipendenze/","page":"Grafo delle Dipendenze","title":"Grafo delle Dipendenze","text":"(Image: image) (Image: image)","category":"page"},{"location":"grafodipendenze/","page":"Grafo delle Dipendenze","title":"Grafo delle Dipendenze","text":"(Image: image)","category":"page"},{"location":"grafodipendenze/","page":"Grafo delle Dipendenze","title":"Grafo delle Dipendenze","text":"(Image: image)","category":"page"},{"location":"grafodipendenze/","page":"Grafo delle Dipendenze","title":"Grafo delle Dipendenze","text":"(Image: image)","category":"page"},{"location":"grafodipendenze/","page":"Grafo delle Dipendenze","title":"Grafo delle Dipendenze","text":"(Image: image)","category":"page"},{"location":"grafodipendenze/","page":"Grafo delle Dipendenze","title":"Grafo delle Dipendenze","text":"(Image: image)","category":"page"},{"location":"grafodipendenze/","page":"Grafo delle Dipendenze","title":"Grafo delle Dipendenze","text":"(Image: image)","category":"page"},{"location":"grafodipendenze/","page":"Grafo delle Dipendenze","title":"Grafo delle Dipendenze","text":"(Image: image)","category":"page"},{"location":"conclusioni/#Conclusioni-e-Sviluppi-Futuri","page":"Conclusione","title":"Conclusioni e Sviluppi Futuri","text":"","category":"section"},{"location":"conclusioni/","page":"Conclusione","title":"Conclusione","text":"Nonostante le modifiche apportate all'algoritmo sostengano maggiormente le prestazioni riducendo il tempo di esecuzione, sviluppi futuri possono prevedere l'impiego di tecnologie come:","category":"page"},{"location":"conclusioni/","page":"Conclusione","title":"Conclusione","text":"'Distributed Workers' - In questo modo i processi Julia verrebbero eseguiti con spazi di memoria separati, garantendo prestazioni ancora maggiori.","category":"page"},{"location":"conclusioni/","page":"Conclusione","title":"Conclusione","text":"'Asynchronous Tasks' - Consentono di sospendere e riprendere i calcoli per I/O e gestione di eventi. I Tasks possono sincronizzarsi tramite la comunicazione per mezzo dei canali.","category":"page"},{"location":"arte/#Situazione-iniziale","page":"Stato dell'arte","title":"Situazione iniziale","text":"","category":"section"},{"location":"arte/","page":"Stato dell'arte","title":"Stato dell'arte","text":"In questo capitolo viene illustrato l'algoritmo TGW2D nel suo stato iniziale ponendo l'enfasi  sulle funzioni principali e su come l'algoritmo sostiene le prestazioni. Inoltre, sono stati utilizzati strumenti di supporto per la profilazione e la misura dei tempi di esecuzione.","category":"page"},{"location":"arte/","page":"Stato dell'arte","title":"Stato dell'arte","text":"La funzione planararrangement è costituita da un codice molto minimale, in quanto la parte più importante dell'esecuzione avviene nelle funzioni esterne che sono chiamate all'interno di essa.  Le funzioni chiamate internamente alla funzione planararrangement sono:","category":"page"},{"location":"arte/","page":"Stato dell'arte","title":"Stato dell'arte","text":"planararrangement1\ncleandecomposition\nbiconnected_components\nplanararrangement2","category":"page"},{"location":"arte/#planar_arrangement","page":"Stato dell'arte","title":"planar_arrangement","text":"","category":"section"},{"location":"arte/","page":"Stato dell'arte","title":"Stato dell'arte","text":"function planar_arrangement(\r\n        V::Lar.Points,\r\n        copEV::Lar.ChainOp,\r\n        sigma::Lar.Chain=spzeros(Int8, 0),\r\n        return_edge_map::Bool=false,\r\n        multiproc::Bool=false)\r\n\r\n\r\n#planar_arrangement_1\r\n\tV,copEV,sigma,edge_map=Lar.Arrangement.planar_arrangement_1(V,copEV,sigma,return_edge_map,multiproc)\r\n\r\n# cleandecomposition\r\n\tif sigma.n > 0\r\n\t\tV,copEV=Lar.Arrangement.cleandecomposition(V, copEV, sigma, edge_map)\r\n\tend\r\n\r\n    bicon_comps = Lar.Arrangement.biconnected_components(copEV)\r\n    # EV = Lar.cop2lar(copEV)\r\n    # V,bicon_comps = Lar.biconnectedComponent((V,EV))\r\n\r\n\tif isempty(bicon_comps)\r\n    \tprintln(\"No biconnected components found.\")\r\n    \tif (return_edge_map)\r\n    \t    return (nothing, nothing, nothing, nothing)\r\n    \telse\r\n    \t    return (nothing, nothing, nothing)\r\n    \tend\r\n\tend\r\n#Planar_arrangement_2\r\n\tV,copEV,FE=Lar.Arrangement.planar_arrangement_2(V,copEV,bicon_comps,edge_map,sigma)\r\n\tif (return_edge_map)\r\n\t     return V, copEV, FE, edge_map\r\n\telse\r\n\t     return V, copEV, FE\r\n\tend\r\nend","category":"page"},{"location":"arte/","page":"Stato dell'arte","title":"Stato dell'arte","text":"L’obiettivo è partizionare un complesso cellulare passato come parametro. Un complesso cellulare è partizionato quando l'intersezione di ogni possibile coppia di celle del complesso è vuota e l'unione di tutte le celle è l'intero spazio euclideo.","category":"page"},{"location":"arte/#biconnected_components","page":"Stato dell'arte","title":"biconnected_components","text":"","category":"section"},{"location":"arte/","page":"Stato dell'arte","title":"Stato dell'arte","text":"Calcola i componenti biconnessi del grafo “EV”, rappresentati dagli spigoli come coppie  di vertici.","category":"page"},{"location":"arte/","page":"Stato dell'arte","title":"Stato dell'arte","text":"Il codice è stato omesso per motivi di compattezza.","category":"page"},{"location":"arte/#cleandecomposition","page":"Stato dell'arte","title":"cleandecomposition","text":"","category":"section"},{"location":"arte/","page":"Stato dell'arte","title":"Stato dell'arte","text":"function cleandecomposition(V, copEV, sigma, edge_map)\r\n    # Deletes edges outside sigma area\r\n    todel = []\r\n    new_edges = []\r\n    map(i->new_edges=union(new_edges, edge_map[i]), sigma.nzind)\r\n    ev = copEV[new_edges, :]\r\n    for e in 1:copEV.m\r\n        if !(e in new_edges)\r\n\r\n            vidxs = copEV[e, :].nzind\r\n            v1, v2 = map(i->V[vidxs[i], :], [1,2])\r\n            centroid = .5*(v1 + v2)\r\n\r\n            if ! Lar.point_in_face(centroid, V, ev)\r\n                push!(todel, e)\r\n            end\r\n        end\r\n    end\r\n\r\n    for i in reverse(todel)\r\n        for row in edge_map\r\n\r\n            filter!(x->x!=i, row)\r\n\r\n            for j in 1:length(row)\r\n                if row[j] > i\r\n                    row[j] -= 1\r\n                end\r\n            end\r\n        end\r\n    end\r\n\r\n    V, copEV = Lar.delete_edges(todel, V, copEV)\r\n\treturn V,copEV\r\nend","category":"page"},{"location":"arte/","page":"Stato dell'arte","title":"Stato dell'arte","text":"Elimina i bordi al di fuori dell'area sigma.","category":"page"},{"location":"arte/#merge_vertices","page":"Stato dell'arte","title":"merge_vertices","text":"","category":"section"},{"location":"arte/","page":"Stato dell'arte","title":"Stato dell'arte","text":"function merge_vertices!(V::Lar.Points, EV::Lar.ChainOp, edge_map, err=1e-4)\r\n    vertsnum = size(V, 1)\r\n    edgenum = size(EV, 1)\r\n    newverts = zeros(Int, vertsnum)\r\n    # KDTree constructor needs an explicit array of Float64\r\n    V = Array{Float64,2}(V)\r\n    kdtree = KDTree(permutedims(V))\r\n\r\n    # merge congruent vertices\r\n    todelete = []\r\n    i = 1\r\n    for vi in 1:vertsnum\r\n        if !(vi in todelete)\r\n            nearvs = Lar.inrange(kdtree, V[vi, :], err)\r\n            newverts[nearvs] .= i\r\n            nearvs = setdiff(nearvs, vi)\r\n            todelete = union(todelete, nearvs)\r\n            i = i + 1\r\n        end\r\n    end\r\n    nV = V[setdiff(collect(1:vertsnum), todelete), :]\r\n\r\n    # merge congruent edges\r\n    edges = Array{Tuple{Int, Int}, 1}(undef, edgenum)\r\n    oedges = Array{Tuple{Int, Int}, 1}(undef, edgenum)\r\n    for ei in 1:edgenum\r\n        v1, v2 = EV[ei, :].nzind\r\n        edges[ei] = Tuple{Int, Int}(sort([newverts[v1], newverts[v2]]))\r\n        oedges[ei] = Tuple{Int, Int}(sort([v1, v2]))\r\n    end\r\n    nedges = union(edges)\r\n    nedges = filter(t->t[1]!=t[2], nedges)\r\n    nedgenum = length(nedges)\r\n    nEV = spzeros(Int8, nedgenum, size(nV, 1))\r\n    # maps pairs of vertex indices to edge index\r\n    etuple2idx = Dict{Tuple{Int, Int}, Int}()\r\n    # builds `edge_map`\r\n    for ei in 1:nedgenum\r\n        nEV[ei, collect(nedges[ei])] .= 1\r\n        etuple2idx[nedges[ei]] = ei\r\n    end\r\n    for i in 1:length(edge_map)\r\n        row = edge_map[i]\r\n        row = map(x->edges[x], row)\r\n        row = filter(t->t[1]!=t[2], row)\r\n        row = map(x->etuple2idx[x], row)\r\n        edge_map[i] = row\r\n    end\r\n    # return new vertices and new edges\r\n    return Lar.Points(nV), nEV\r\nend","category":"page"},{"location":"arte/","page":"Stato dell'arte","title":"Stato dell'arte","text":"Si occupa di fondere vertici congruenti e bordi congruenti, assegnare a coppie di indici di vertici indici di bordo e costruire una mappa dei bordi.","category":"page"},{"location":"arte/#Come-migliorare-il-codice","page":"Stato dell'arte","title":"Come migliorare il codice","text":"","category":"section"},{"location":"arte/","page":"Stato dell'arte","title":"Stato dell'arte","text":"Analizzando il codice nel dettaglio, è possibile evidenziare che in alcuni passi dell'algoritmo è stato implementato il calcolo parallelo e distribuito. Infatti, nella funzione \"planararrangement1\", la frammentazione dei bordi può essere effettuata tramite il calcolo asincrono. Continuando l'analisi del codice ed osservando accuratamente le dipendenze presenti risulta opportuno implementare modifiche con l'obiettivo di migliorare scalabilità, modificabilità e prestazioni di porzioni dello stesso, riducendo l'accoppiamento tra i moduli presenti fattorizzando il codice e continuando ad implementare forme di calcolo parallelo e distribuito. In particolare, alcune di queste modifiche dovranno coinvolgere il  codice relativo alla funzione \"merge_vertices!\", presentata in precedenza. Infatti, ad essa sono assegnate numerose task che possono essere suddivise in diverse sotto funzioni.","category":"page"},{"location":"#TGW2D","page":"Informazioni Generali","title":"TGW2D","text":"","category":"section"},{"location":"","page":"Informazioni Generali","title":"Informazioni Generali","text":"Progetto Topological Gift Wrapping 2D per Calcolo Parallelo e Distribuito sviluppato da:","category":"page"},{"location":"","page":"Informazioni Generali","title":"Informazioni Generali","text":"Nome Matricola E-mail Github Profile\nMatteo Maraziti 534932 mat.maraziti@stud.uniroma3.it https://github.com/matteomaraziti\nFederico Tocci 533449 fed.tocci@stud.uniroma3.it https://github.com/FTocci\nGiacomo Scordino 533393 gia.scordino1@stud.uniroma3.it https://github.com/GiacomoScordino","category":"page"},{"location":"","page":"Informazioni Generali","title":"Informazioni Generali","text":"Documentazione: https://ftocci.github.io/TGW2D/build/  ","category":"page"},{"location":"","page":"Informazioni Generali","title":"Informazioni Generali","text":"Repository: https://github.com/FTocci/TGW2D","category":"page"},{"location":"","page":"Informazioni Generali","title":"Informazioni Generali","text":"Notebooks:","category":"page"},{"location":"","page":"Informazioni Generali","title":"Informazioni Generali","text":"Studio Preliminare: https://github.com/FTocci/TGW2D/blob/main/notebooks/NotebookPreliminare.ipynb\nStudio Esecutivo - Finale: https://github.com/FTocci/TGW2D/blob/main/notebooks/NotebookFinale.ipynb","category":"page"},{"location":"#Rapid-Explanation-(for-English-Users)","page":"Informazioni Generali","title":"Rapid Explanation (for English Users)","text":"","category":"section"},{"location":"","page":"Informazioni Generali","title":"Informazioni Generali","text":"The Topological Gift Wrapping repository contains functions for computing the arrangement on the given cellular complex 1-skeleton in 2D. A cellular complex is arranged when the intersection of every possible pair of cell of the complex is empty and the union of all the cells is the whole Euclidean space. The basic method of the function without the sigma, return_edge_map and multiproc arguments returns the full arranged complex V, EV and FE.","category":"page"}]
}
